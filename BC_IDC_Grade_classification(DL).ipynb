{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT9lQ5QD5E-B"
      },
      "source": [
        "### IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMHNqDxt5E-Q"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import os\n",
        "import tqdm\n",
        "import glob\n",
        "import tensorflow\n",
        "import keras\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.color import grey2rgb\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,  ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import VGG16,EfficientNetB2,ResNet50\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH6svpX65cNr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjLi3ffYSsmt"
      },
      "source": [
        "!pip install git+https://github.com/qubvel/efficientnet.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FePUvF_05E-T"
      },
      "source": [
        "### IMPORT / VIEWING / PREPROCESSING DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l55ES6FN5E-V"
      },
      "source": [
        "> `DATA AUGMENTATION`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-lm-395b_dr"
      },
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [   keras.layers.experimental.preprocessing.RandomZoom(-0.3,-0.2),\n",
        "        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "        keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    ]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK6-ERSN5E-W"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "\n",
        "                                   )\n",
        "\n",
        "\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLZgOh285E-X"
      },
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = '/content/drive/MyDrive/BC_IDC/train',\n",
        "                                                   target_size = (512,512),\n",
        "                                                   class_mode = 'categorical',\n",
        "\n",
        "                                                   batch_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z00vBR2o5E-a"
      },
      "source": [
        "test_dataset = test_datagen.flow_from_directory(directory = '/content/drive/MyDrive/BC_IDC/test',\n",
        "                                                  target_size = (512,512),\n",
        "                                                  class_mode = 'categorical',\n",
        "\n",
        "                                                  batch_size = 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gf0eXpx5E-e"
      },
      "source": [
        "### MODEL BUILDING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4AgsKgoyPfe"
      },
      "source": [
        "def f1_score(y_true, y_pred): #taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaZNz4IY5E-e"
      },
      "source": [
        "# Model Initialization\n",
        "import keras\n",
        "\n",
        "modelpath = '/content/drive/MyDrive/ResNet50pretrained_imagnet_finetuning_weights.h5'\n",
        "base_model = keras.models.load_model(modelpath)\n",
        "base_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iGgPIAKu25l"
      },
      "source": [
        "\n",
        "#base_model.get_layer(name='resnet50').name = 'resnet50'\n",
        "input  = keras.Input(shape=(512,512,3))\n",
        "x = data_augmentation(input)\n",
        "for layer in base_model.layers[0].layers[1:]:\n",
        "  x = layer(x)\n",
        "for layers in base_model.layers[1:-1]:\n",
        "  x = layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3LjuPIX-tGd"
      },
      "source": [
        "\n",
        "\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR9-w4ynkqhD"
      },
      "source": [
        "def change_model(model, new_input_shape=(None, 40, 40, 3),custom_objects=None):\n",
        "    # replace input shape of first layer\n",
        "\n",
        "    config = model.layers[0].layers[0].get_config()\n",
        "    config['batch_input_shape']=new_input_shape\n",
        "    model.layers[0]._layers[0]=model.layers[0].layers[0].from_config(config)\n",
        "\n",
        "    # rebuild model architecture by exporting and importing via json\n",
        "    new_model = tensorflow.keras.models.model_from_json(model.to_json(),custom_objects=custom_objects)\n",
        "\n",
        "    # copy weights from old model to new one\n",
        "    for layer in new_model._layers:\n",
        "        try:\n",
        "            layer.set_weights(model.get_layer(name=layer.name).get_weights())\n",
        "            print(\"Loaded layer {}\".format(layer.name))\n",
        "        except:\n",
        "            print(\"Could not transfer weights for layer {}\".format(layer.name))\n",
        "\n",
        "    return new_model\n",
        "new_model = change_model(base_model, new_input_shape=[None] + [512,512,3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eISjHIoRsi6K"
      },
      "source": [
        "base_model = keras.applications.ResNet50(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(512, 512, 3),\n",
        "    include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q5QWL-SIBq0"
      },
      "source": [
        "for layer in new_model.layers[0].layers[:143]:\n",
        "  layer.trainable = False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKeLIqEl_ig1"
      },
      "source": [
        "base_model.layers[0].summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFDAC8YKTzX-"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(new_model)\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(3,activation='softmax'))\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGodDIkYSMIq"
      },
      "source": [
        "inputs = keras.Input(shape=(512, 512, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = base_model(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x =  Dropout(0.5)(x)\n",
        "outputs = keras.layers.Dense(3,activation='softmax')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpaayzaMJZdk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5,name = 'dropout_1')(x)\n",
        "x = Dense(64,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5,name = 'dropout_2')(x)\n",
        "x = Dense(64,kernel_initializer='he_uniform')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Dropout(0.5,name = 'dropout_3')(x)\n",
        "outputs = Dense(3,activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(input, outputs)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clluMdxd5E-f"
      },
      "source": [
        "# Freezing Layers\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_p72jaLBYUt"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOyLqB8x5E-g"
      },
      "source": [
        "# Building Model\n",
        "\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Dense(64,kernel_initializer='he_uniform'))\n",
        "x=model.add(BatchNormalization())\n",
        "x=model.add(Activation('relu'))\n",
        "x=model.add(Dropout(0.5))\n",
        "x=model.add(Dense(64,kernel_initializer='he_uniform'))\n",
        "x=model.add(BatchNormalization())\n",
        "x=model.add(Activation('relu'))\n",
        "x=model.add(Dropout(0.5))\n",
        "x=model.add(Dense(64,kernel_initializer='he_uniform'))\n",
        "x=model.add(BatchNormalization())\n",
        "x=model.add(Activation('relu'))\n",
        "x=model.add(Dropout(0.5))\n",
        "x=model.add(Dense(3,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za_DHKyT5E-h"
      },
      "source": [
        "# Summary\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2RfPYsH5E-i"
      },
      "source": [
        "# Model Compile\n",
        "\n",
        "OPT    = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'),\n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc')\n",
        "]\n",
        "\n",
        "base_model.compile(loss='categorical_crossentropy',\n",
        "              metrics= METRICS,\n",
        "              optimizer=OPT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2M7AFR55E-j"
      },
      "source": [
        "# Defining Callbacks\n",
        "\n",
        "filepath = '/content/drive/MyDrive/ResNet50pretrained2_imagnet_finetuning_weights.h5'\n",
        "\n",
        "earlystopping = EarlyStopping(monitor = 'val_accuracy',\n",
        "                              mode = 'max' ,\n",
        "                              patience = 60,\n",
        "                              verbose = 1)\n",
        "\n",
        "checkpoint    = ModelCheckpoint(filepath,\n",
        "                                monitor = 'val_accuracy',\n",
        "                                mode='max',\n",
        "                                save_best_only=True,\n",
        "                                verbose = 1)\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 5,verbose = 1,factor = 0.75, min_lr = 1e-10)\n",
        "\n",
        "\n",
        "callback_list = [earlystopping, checkpoint, lrd]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbw0AaEH5E-k"
      },
      "source": [
        "model_history=base_model.fit(train_dataset,\n",
        "                        validation_data=test_dataset,\n",
        "                        epochs = 100,\n",
        "                        callbacks = callback_list,\n",
        "                        verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Qcxmpr5E-l"
      },
      "source": [
        "### MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl47QqOr5E-m"
      },
      "source": [
        "# Summarize history for loss\n",
        "\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKZFZaZa5E-m"
      },
      "source": [
        "# Summarize history for loss\n",
        "\n",
        "plt.plot(model_history.history['auc'])\n",
        "plt.plot(model_history.history['val_auc'])\n",
        "plt.title('Model AUC')\n",
        "plt.ylabel('AUC')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left', bbox_to_anchor=(1,1))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_6HYAFI9d5T"
      },
      "source": [
        "# Improting Image class from PIL module\n",
        "from PIL import Image\n",
        "\n",
        "# Opens a image in RGB mode\n",
        "#im = Image.open(r\"/content/drive/MyDrive/BC_IDC/train/G1/01_BC_G1_9057_10x_1.JPG\")\n",
        "\n",
        "# importing the module\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import glob\n",
        "PATH = '/content/drive/MyDrive/BC_IDC/40x/train_original/G1_cropped'\n",
        "for filename in glob.glob('/content/drive/MyDrive/BC_IDC/40x/train_original/G1/*.*'):\n",
        "\n",
        "  img=cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  height,width=img.shape[:2]\n",
        "  cv2_imshow(img)\n",
        "\n",
        "\n",
        "  start_row,start_col=int(width*0),int(height*0.1)\n",
        "  end_row,end_col=int(width*1),int(height*1)\n",
        "\n",
        "\n",
        "  cropped=img[start_row:-1,start_col:-50]\n",
        "\n",
        "  cv2.imwrite(os.path.join(PATH , filename), cropped)\n",
        "  cv2_imshow(cropped)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RALP30up9qcy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "\n",
        "img = cv2.imread('/content/drive/MyDrive/BC_IDC/40x/train_40x/G1/01_BC_G1_9057_40x_1_JPG.rf.3b7f25e2099e04523f2d671b37ee8202.jpg', cv2.IMREAD_UNCHANGED)\n",
        "#cv2.putText(img,\"original image\")\n",
        "cv2_imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F43COHwRd8C"
      },
      "source": [
        "%matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xoplv2mbrfFH"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5rVe75orjqm"
      },
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "PATH = '/content/drive/MyDrive/BC_IDC/40x/train_original/G3'\n",
        "for filename in glob.glob('/content/drive/MyDrive/BC_IDC/40x/train_original/G3/*.*'):\n",
        "\n",
        "\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    w,h = img.size\n",
        "    (left, upper, right, lower) = (w*0.08, h*0.066, w*0.84, h*1)\n",
        "    im_crop  = img.crop((left, upper, right, lower))\n",
        "    im_crop.save(os.path.join(PATH,filename))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing deepslide framework on this dataset**\n",
        "\n",
        "**DeepSlide: A Sliding Window Framework for Classification of High Resolution Microscopy Images**\n",
        "[github repo link](https://github.com/BMIRDS/deepslide.git)\n"
      ],
      "metadata": {
        "id": "_HWKqBuGztsQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwdozPENr6yu"
      },
      "source": [
        "!git clone https://github.com/BMIRDS/deepslide.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxv5_-86F3aK"
      },
      "source": [
        "%cd /content/deepslide"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcprjYMqF8OJ"
      },
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python code/4_test.py --all_wsi  /content/drive/MyDrive/20x/20x_all \\\n",
        "               --auto_select False \\\n",
        "               --preds_test   /content/drive/MyDrive/20x/pred_test \\\n",
        "               --preds_val /content/drive/MyDrive/20x/pred_val \\\n",
        "               --num_layers 18 \\\n",
        "               --patches_eval_val /content/drive/MyDrive/20x/val_patches \\\n",
        "               --patches_eval_test /content/drive/MyDrive/20x/test_patches \\\n",
        "               --checkpoints_folder /content/drive/MyDrive/checkpoints/20x_checkpoint/65 \\\n",
        "               --checkpoint_file   resnet18_e65_va0.66948.pt \\\n",
        "               --num_workers 8 --batch_size 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph9eIxITI0CD"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "!python code/5_grid_search.py --all_wsi  /content/drive/MyDrive/20x/20x_all \\\n",
        "               --preds_val /content/drive/MyDrive/20x/pred_val \\\n",
        "               --inference_val   /content/drive/MyDrive/20x/inference_val\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cLdlgRg5icA"
      },
      "source": [
        "!python code/6_visualize.py --all_wsi  /content/drive/MyDrive/20x/20x_all \\\n",
        "               --wsi_val /content/drive/MyDrive/20x/valid_20x \\\n",
        "               --preds_val /content/drive/MyDrive/20x/pred_val \\\n",
        "               --wsi_test  /content/drive/MyDrive/20x/test_20x \\\n",
        "               --preds_test /content/drive/MyDrive/20x/pred_test \\\n",
        "               --vis_val /content/drive/MyDrive/20x/vis_val \\\n",
        "               --vis_test /content/drive/MyDrive/20x/vis_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XzweHVcg9Iy0"
      },
      "source": [
        "!python code/7_final_test.py --all_wsi /content/drive/MyDrive/20x/20x_all \\\n",
        "--inference_val /content/drive/MyDrive/20x/inference_val \\\n",
        "--labels_val /content/drive/MyDrive/20x/labels/valid_labels_20x.csv \\\n",
        "--labels_test /content/drive/MyDrive/20x/labels/test_labels_20x.csv \\\n",
        "--preds_test /content/drive/MyDrive/20x/pred_test \\\n",
        "--inference_test /content/drive/MyDrive/20x/inference_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUPqVyCwkkHU"
      },
      "source": [
        "--all_wsi /content/drive/MyDrive/BC_IDC/40x/40x_all \\\n",
        "                    --inference_val  /content/drive/MyDrive/BC_IDC/40x/inference_val \\\n",
        "                    --labels_val /content/drive/MyDrive/BC_IDC/40x/labels/valid_labels.csv \\\n",
        "                    --preds_test /content/drive/MyDrive/BC_IDC/40x/pred_test_csv \\\n",
        "                    --inference_test /content/drive/MyDrive/BC_IDC/40x/inference_test \\\n",
        "                    --labels_test  /content/drive/MyDrive/BC_IDC/40x/labels/test_labels.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buER0GEeAEOp"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "img_to_label = []\n",
        "header = ['img', 'gt']\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/BC_IDC/40x/test_40x'):\n",
        "\n",
        "  for name in files:\n",
        "    label = os.path.join(root,name).split('/')[-2]\n",
        "    img_name = os.path.join(root,name).split('/')[-1].split('.')[0] + '.jpg'\n",
        "    rows = [img_name,label]\n",
        "    img_to_label.append(rows)\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/BC_IDC/40x/labels/test_labels.csv','w') as label_file:\n",
        "      csv_writer = csv.writer(label_file)\n",
        "      csv_writer.writerow(header)\n",
        "      csv_writer.writerows(sorted(img_to_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsGGMAc8AJzw"
      },
      "source": [
        "!python /content/deepslide/code/1_split.py  --all_wsi  40x_all/ \\\n",
        "                         --labels_test labels/labels_test.csv \\\n",
        "                         --labels_train labels/labels_train.csv \\\n",
        "                         --labels_val labels/labels_val.csv \\\n",
        "                         --wsi_test ex_test/ \\\n",
        "                         --wsi_train ex_train/ \\\n",
        "                         --wsi_val ex_val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5tvH9wqw7d"
      },
      "source": [
        "%cd /content/drive/MyDrive/BC_IDC/40x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCMUesHetyjc"
      },
      "source": [
        "\n",
        "with open('/content/drive/MyDrive/BC_IDC/40x/labels/valid_labels.csv','r') as lines_open:\n",
        "\n",
        "        lines = lines_open.readlines()[1:]\n",
        "\n",
        "        file_to_gt_label = {}\n",
        "\n",
        "        for line in lines[0:3]:\n",
        "            if len(line) > 3:\n",
        "                pieces = line[:-1].split(\",\")\n",
        "                print(pieces)\n",
        "                file = pieces[0]\n",
        "                gt_label = pieces[1]\n",
        "\n",
        "                file_to_gt_label[file] = gt_label\n",
        "                print(file_to_gt_label)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ_T0LHtwR6c"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}